{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Pandas for data wrangling\n",
      "\n",
      "_Prepared by: Suzanne Kiihne, based previous by Cindee Madison, ...  _\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Introduction\n",
      "\n",
      "\n",
      "We will use **pandas** package to investigate some data. This will introduce \n",
      "\n",
      "1. reading data from CSV or Excell formats\n",
      "2. common data cleanup:  select, delete, rename, fill in #NA\n",
      "3. basic statistics\n",
      "4. a simple plot\n",
      "5. writing out data\n",
      "\n",
      "\n",
      "Go ahead and get the data at: (http://swcarpentry.github.io/2014-04-14-wise/novice/python/scidata.zip)\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Pandas\n",
      "\n",
      "There are *several* packages for dealing with structured data more intelligently than raw Numpy arrays. However, in recent years, the Python Data Analysis Library &em [Pandas](http://pandas.pydata.org/) has risen to the top for its general usability and flexibility.\n",
      "\n",
      "Pandas has excellent I/O functionality, which can read data from many different formats, including web streaming data and databases: csv, excell, JSON, HTML, mySQL, or HDF... The main data structure in Pandas is known as the `DataFrame`, which will seem familiar if you have done statistical computing in [R](http://www.r-project.org). Pandas helps you store, manipulate, filter, etc, all kinds of data .... even when its messy! It also produces high quality plots with [matplotlib](http://matplotlib.org/), and it integrates nicely with other libraries that expect NumPy arrays.\n",
      "\n",
      ">Note - Pandas can do *a lot*, and it's a very complicated package to understand in full.  If you want to do more than we show here, check out the [extensive documentation](http://pandas.pydata.org/pandas-docs/stable/) online (though be prepared for a relatively steep learning curve).\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# setting up our environment\n",
      "try:\n",
      "    %matplotlib inline\n",
      "except:\n",
      "    %pylab inline\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 120
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Excel Files\n",
      "\n",
      "Pandas can read Excel Files! Excel Files can hold multiple **sheets**, but Pandas `DataFrames` don't, so we need to do three things:\n",
      "\n",
      "1. read in the data\n",
      "2. parse the sheet names\n",
      "3. select the sheet we want to **parse**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# read the data from the Excel file\n",
      "excelfile = pd.ExcelFile('scidata/TSveg_all.xls')\n",
      "\n",
      "# get the sheet names\n",
      "excelfile.sheet_names"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 121,
       "text": [
        "[u'transects', u'quads', u'2006 unknowns', u'species list']"
       ]
      }
     ],
     "prompt_number": 121
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# read a sheet into a data frame with the parse function\n",
      "# note: header is an optional parameter -- what happens if you leave it out?\n",
      "df = excelfile.parse('species list', header=1)\n",
      "\n",
      "# we can get an overview of the data with info()\n",
      "df.info()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Int64Index: 48 entries, 0 to 47\n",
        "Data columns (total 4 columns):\n",
        "Spp. Code          47 non-null object\n",
        "Common Name        45 non-null object\n",
        "Scientific Name    34 non-null object\n",
        "Unnamed: 3         1 non-null object\n",
        "dtypes: object(4)"
       ]
      }
     ],
     "prompt_number": 122
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# and get a peek at the values with head()\n",
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Spp. Code</th>\n",
        "      <th>Common Name</th>\n",
        "      <th>Scientific Name</th>\n",
        "      <th>Unnamed: 3</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> ANAR</td>\n",
        "      <td>   Scarlet pimpernel</td>\n",
        "      <td>    Anagallis arvensis</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> ATSE</td>\n",
        "      <td> Australian saltbush</td>\n",
        "      <td>  Atriplex semibaccata</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> ATTR</td>\n",
        "      <td>             Fat hen</td>\n",
        "      <td> Atriplex triangularis</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> BAPI</td>\n",
        "      <td>         coyote bush</td>\n",
        "      <td>   Baccharis pilularis</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> BRHO</td>\n",
        "      <td>          Soft chess</td>\n",
        "      <td>    Bromus hordeaceous</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 4 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 123,
       "text": [
        "  Spp. Code          Common Name        Scientific Name Unnamed: 3\n",
        "0      ANAR    Scarlet pimpernel     Anagallis arvensis        NaN\n",
        "1      ATSE  Australian saltbush   Atriplex semibaccata        NaN\n",
        "2      ATTR              Fat hen  Atriplex triangularis        NaN\n",
        "3      BAPI          coyote bush    Baccharis pilularis        NaN\n",
        "4      BRHO           Soft chess     Bromus hordeaceous        NaN\n",
        "\n",
        "[5 rows x 4 columns]"
       ]
      }
     ],
     "prompt_number": 123
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We want to be able to look into our data and find out what the values are. We can select columns with the column names. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get the column names\n",
      "df.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 124,
       "text": [
        "Index([u'Spp. Code', u'Common Name', u'Scientific Name', u'Unnamed: 3'], dtype='object')"
       ]
      }
     ],
     "prompt_number": 124
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# select a column\n",
      "df['Scientific Name']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 125,
       "text": [
        "0            Anagallis arvensis\n",
        "1          Atriplex semibaccata\n",
        "2         Atriplex triangularis\n",
        "3           Baccharis pilularis\n",
        "4            Bromus hordeaceous\n",
        "5                 Brassica rapa\n",
        "6        Centaurea solstitialis\n",
        "7          Cotula coronopifolia\n",
        "8            Distichlis spicata\n",
        "9                Festuca myuros\n",
        "10             Frankenia salina\n",
        "11            Grindelia stricta\n",
        "12         Hypochaeris radicata\n",
        "13               Jaumea carnosa\n",
        "14                          NaN\n",
        "15             Lactuca serriola\n",
        "16           Lotus corniculatus\n",
        "17           Lolium multiflorum\n",
        "18               Lolium perenne\n",
        "19             Picris echioides\n",
        "20        Polygonum arenastrum \n",
        "21          Polygonum marinense\n",
        "22      Polypogon monspeliensis\n",
        "23             Raphanus sativus\n",
        "24                Rumex crispus\n",
        "25         Salicornia virginica\n",
        "26         Sarcocornia pacifica\n",
        "27             Spartina foliosa\n",
        "28           Sperugula arvensis\n",
        "29       Spergularia macrotheca\n",
        "30            Spergularia rubra\n",
        "31    Tetragonia tetragonioides\n",
        "32                 Ulva lactusa\n",
        "33                 Vicia sativa\n",
        "34               Cuscuta salina\n",
        "35                          NaN\n",
        "36                          NaN\n",
        "37                          NaN\n",
        "38                          NaN\n",
        "39                          NaN\n",
        "40                          NaN\n",
        "41                          NaN\n",
        "42                          NaN\n",
        "43                          NaN\n",
        "44                          NaN\n",
        "45                          NaN\n",
        "46                          NaN\n",
        "47                          NaN\n",
        "Name: Scientific Name, dtype: object"
       ]
      }
     ],
     "prompt_number": 125
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Rows can be selected with the .ix function. We're still using python, so slicing works well."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.ix[33:37]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Spp. Code</th>\n",
        "      <th>Common Name</th>\n",
        "      <th>Scientific Name</th>\n",
        "      <th>Unnamed: 3</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>33</th>\n",
        "      <td>        VISA</td>\n",
        "      <td>      Common vetch</td>\n",
        "      <td>   Vicia sativa</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>34</th>\n",
        "      <td>        CUSA</td>\n",
        "      <td> Salt Marsh Dodder</td>\n",
        "      <td> Cuscuta salina</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>35</th>\n",
        "      <td>         NaN</td>\n",
        "      <td>               NaN</td>\n",
        "      <td>            NaN</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>36</th>\n",
        "      <td> Other Codes</td>\n",
        "      <td>               NaN</td>\n",
        "      <td>            NaN</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>37</th>\n",
        "      <td>        ALGB</td>\n",
        "      <td>       Brown Algae</td>\n",
        "      <td>            NaN</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 4 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 126,
       "text": [
        "      Spp. Code        Common Name Scientific Name Unnamed: 3\n",
        "33         VISA       Common vetch    Vicia sativa        NaN\n",
        "34         CUSA  Salt Marsh Dodder  Cuscuta salina        NaN\n",
        "35          NaN                NaN             NaN        NaN\n",
        "36  Other Codes                NaN             NaN        NaN\n",
        "37         ALGB        Brown Algae             NaN        NaN\n",
        "\n",
        "[5 rows x 4 columns]"
       ]
      }
     ],
     "prompt_number": 126
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# row 35 has no information. \n",
      "# We can drop rows that are all NaN with the dropna() function. \n",
      "# If we don't specify how='all', it will drop rows with any NaN, which would be all our data!\n",
      "df.dropna(how='all')[34:37]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Spp. Code</th>\n",
        "      <th>Common Name</th>\n",
        "      <th>Scientific Name</th>\n",
        "      <th>Unnamed: 3</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>34</th>\n",
        "      <td>        CUSA</td>\n",
        "      <td> Salt Marsh Dodder</td>\n",
        "      <td> Cuscuta salina</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>36</th>\n",
        "      <td> Other Codes</td>\n",
        "      <td>               NaN</td>\n",
        "      <td>            NaN</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>37</th>\n",
        "      <td>        ALGB</td>\n",
        "      <td>       Brown Algae</td>\n",
        "      <td>            NaN</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>3 rows \u00d7 4 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 127,
       "text": [
        "      Spp. Code        Common Name Scientific Name Unnamed: 3\n",
        "34         CUSA  Salt Marsh Dodder  Cuscuta salina        NaN\n",
        "36  Other Codes                NaN             NaN        NaN\n",
        "37         ALGB        Brown Algae             NaN        NaN\n",
        "\n",
        "[3 rows x 4 columns]"
       ]
      }
     ],
     "prompt_number": 127
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###CSV Files\n",
      "\n",
      "Pandas reads many formats, and plain text CSV files are another common format. Let's look at some more interesting  data. CSV files are variable, so the `read_csv` function has a large number of control parameters to change its behaviour:  \n",
      "\n",
      "1. sep : default is comma, but you can specify '\\t' (tab) or if unsure, try sep=None\n",
      "2. skiprows : sometimes you want to skip a couple rows, eg skiprows = 2\n",
      "\n",
      "To find all the options  \n",
      "    pd.read_csv?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# peek into the data with the shell\n",
      "!head scidata/TSveg_short.csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "East,North,Year,Season,Date,Transect,Quad,DIST.,Water Depth,Spp,Common Name,Scientific Name,Percent,Height,Density,Obs,Comments\r",
        "\r\n",
        "549717,4219841,2002,Summer,8/23/2002,1,1,6,,RASA,Common wild radish,Raphanus sativus,25,34,1,CR;SD,\r",
        "\r\n",
        "549717,4219841,2002,Summer,8/23/2002,1,7,21,,BARE,bare ground,N/A,35,,,CR;SD,\r",
        "\r\n",
        "549717,4219841,2002,Summer,8/23/2002,1,8,24,54,SAVI,Pickleweed,Salicornia virginica,25,33,50,CR;SD,\r",
        "\r\n",
        "549526,4219628,2002,Summer,8/23/2002,3A,3,6,,ATTR,Fat hen,Atriplex triangularis,60,24,2,CR;SD,\r",
        "\r\n",
        "549526,4219628,2002,Summer,8/23/2002,3A,3,6,,BARE,bare ground,N/A,40,,,CR;SD,\r",
        "\r\n",
        "549716,4219834,2003,SPRING,5/16/2003,1A,9,24,2,BARE,bare ground,N/A,15,,1A,AW ; CR,\r",
        "\r\n",
        "549716,4219834,2003,SPRING,5/16/2003,1A,10,27,,SAVI,Pickleweed,Salicornia virginica,15,34,1A,AW ; CR,\r",
        "\r\n",
        "549909,4219899,2003,Summer,8/27/2003,2A,13,36,,SAVI,Pickleweed,Salicornia virginica,1,8,2,AW ; CR,\r",
        "\r\n",
        "549909,4219899,2003,Summer,8/27/2003,2A,14,39,,MF,mudflat,N/A,100,,,AW ; CR,\r",
        "\r\n"
       ]
      }
     ],
     "prompt_number": 135
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Next we will read in the data from the CSV file.\n",
      "# Pandas has inherent fanciness that displays data in nice tabular format.\n",
      "csv_file = 'scidata/TSveg_short.csv'\n",
      "df1 = pd.read_csv(csv_file)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 136
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Themes and variations\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df1.info()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Int64Index: 9 entries, 0 to 8\n",
        "Data columns (total 17 columns):\n",
        "East               9 non-null int64\n",
        "North              9 non-null int64\n",
        "Year               9 non-null int64\n",
        "Season             9 non-null object\n",
        "Date               9 non-null object\n",
        "Transect           9 non-null object\n",
        "Quad               9 non-null int64\n",
        "DIST.              9 non-null int64\n",
        "Water Depth        2 non-null float64\n",
        "Spp                9 non-null object\n",
        "Common Name        9 non-null object\n",
        "Scientific Name    5 non-null object\n",
        "Percent            9 non-null int64\n",
        "Height             5 non-null float64\n",
        "Density            6 non-null object\n",
        "Obs                9 non-null object\n",
        "Comments           0 non-null float64\n",
        "dtypes: float64(3), int64(6), object(8)"
       ]
      }
     ],
     "prompt_number": 137
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Columns\n",
      "\n",
      "Data frames have columns and rows. Usually we try to keep different instances of the data in the rows and different types of data in the columns. Pandas gives two ways of addressing the data columns:\n",
      "\n",
      "* Using the column name as an attribute reference (Note: this works only if the column name is a simple word that doesn't conflict with another function name. What happens if we have a column 'len'?)\n",
      "\n",
      "    ``` \n",
      "    df.Animal\n",
      "    ```\n",
      "   \n",
      "* Like a python dictionary: passing the name of the column as a string\n",
      "\n",
      "    ```\n",
      "    df['Animal']\n",
      "    ```\n",
      "    \n",
      "It is often necessary to clean up column names from messy data. Python has many string function that can automate this, and pandas allows you to select the column names easily. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get the column names\n",
      "names1 = df1.columns\n",
      "names1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 138,
       "text": [
        "Index([u'East', u'North', u'Year', u'Season', u'Date', u'Transect', u'Quad', u'DIST.', u'Water Depth', u'Spp', u'Common Name', u'Scientific Name', u'Percent', u'Height', u'Density', u'Obs', u'Comments'], dtype='object')"
       ]
      }
     ],
     "prompt_number": 138
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Since these names are going to be useful addresses into our data, we need to clean them up. We can do this by removing spaces and changing to lower case for ease of typing. The we have the column names in a list, so we can easily do this with string functions in a list comprehension."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# clean up column names\n",
      "# to lower case:\n",
      "corrected = []\n",
      "for s in names1:\n",
      "    corrected.append(s.lower())\n",
      "    # what other cleanup might we need?\n",
      "df1.columns = corrected\n",
      "df1.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 140,
       "text": [
        "Index([u'east', u'north', u'year', u'season', u'date', u'transect', u'quad', u'dist.', u'water depth', u'spp', u'common name', u'scientific name', u'percent', u'height', u'density', u'obs', u'comments'], dtype='object')"
       ]
      }
     ],
     "prompt_number": 140
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.water depth"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Working with Dates\n",
      "Pandas is used for a lot of financial data, including reports and data releases from companies and government agencies. Many of these come out periodically, but on different time scales, so Pandas has very good tools for interpreting dates and justifying and interpolating timescales. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df1.date[5:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 142,
       "text": [
        "5    5/16/2003\n",
        "6    5/16/2003\n",
        "7    8/27/2003\n",
        "8    8/27/2003\n",
        "Name: date, dtype: object"
       ]
      }
     ],
     "prompt_number": 142
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Import the datetime class from the datetime module\n",
      "from datetime import datetime\n",
      "\n",
      "# Convert date string to datetime object\n",
      "datetime.strptime(df1.date[6], \"%m/%d/%Y\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 141,
       "text": [
        "datetime.datetime(2003, 5, 16, 0, 0)"
       ]
      }
     ],
     "prompt_number": 141
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Using the `apply()` method, which takes a function (**without** the parentheses), we can apply `strptime` to each value in the column. We'll overwrite the string date values with their Python `datetime` equivalents."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Define a function to convert strings to dates\n",
      "def string_to_date(date_string):\n",
      "    return datetime.strptime(date_string, \"%m/%d/%Y\")\n",
      "\n",
      "# Run the function on every date string and overwrite the column\n",
      "df1.date = df1['date'].apply(string_to_date)\n",
      "\n",
      "df1.date"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 143,
       "text": [
        "0   2002-08-23\n",
        "1   2002-08-23\n",
        "2   2002-08-23\n",
        "3   2002-08-23\n",
        "4   2002-08-23\n",
        "5   2003-05-16\n",
        "6   2003-05-16\n",
        "7   2003-08-27\n",
        "8   2003-08-27\n",
        "Name: date, dtype: datetime64[ns]"
       ]
      }
     ],
     "prompt_number": 143
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Comparisons:\n",
      "We often want to compare and contrast two sets of data. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Let's read in a second CSV file\n",
      "csv_file = 'scidata/GCveg_short.csv'\n",
      "df2 = pd.read_csv(csv_file)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 133
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df2.info()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We need to do the same steps here that we did with df1:  cleaning up the naming and changing the dates from strings to machine-readable dates."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "names2 = df2.columns\n",
      "df2.date = df2['date'].apply(string_to_date)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# clean up column names\n",
      "# to lower case:\n",
      "corrected = [s.lower() for s in names2]\n",
      "# remove white space at the ends\n",
      "corrected = [s.strip() for s in corrected]\n",
      "# remove spaces in the middle\n",
      "corrected = [''.join(s.split()) for s in corrected]\n",
      "# remove any .'s in column names\n",
      "corrected = [s.strip('.') for s in corrected]\n",
      "# assign the column names for the dataset to the clean names\n",
      "df2.columns = corrected\n",
      "df2.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 42,
       "text": [
        "Index([u'date', u'year', u'month', u'season', u'habitat', u'transect', u'quadrat', u'spp', u'commonname', u'scientificname', u'%cover', u'height', u'density', u'waterdepth', u'easting', u'northing', u'notes'], dtype='object')"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Think like a programmer: \n",
      "That's really ugly. And we had to do it **twice**. \n",
      "\n",
      ">There was a question last night at the reception: how do I move on from here? What we just did is a _red flag_! This process needs help. Is there already a general method of cleaning column names in `pandas`? Maybe, I don't know... If there is, we should be using it. If there isn't we should write it! Hey, what if we could just tell read_csv to clean column names on import? How cool would that be?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# we still need to justify the column names between the two data frames.\n",
      "# there are probably some more that I missed.... \n",
      "corrected[10] = 'percent'\n",
      "df2.columns = corrected\n",
      "df2.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 71,
       "text": [
        "Index([u'date', u'year', u'month', u'season', u'habitat', u'transect', u'quadrat', u'spp', u'commonname', u'scientificname', u'percent', u'height', u'density', u'waterdepth', u'easting', u'northing', u'notes'], dtype='object')"
       ]
      }
     ],
     "prompt_number": 71
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Subsetting and pulling out values\n",
      "What if we only care about one species attribute? We can use logical comparisons to create a 'mask' and select out the data corresponding to that group. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# create a new dataframe that only contains Owl data\n",
      "bare_mask = df1.spp == 'BARE'\n",
      "bare1 = df1[bare_mask]\n",
      "\n",
      "bare_mask = df2.spp == 'BARE'\n",
      "bare2 = df2[bare_mask]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 97
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# how does it work?\n",
      "bare_mask"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 144,
       "text": [
        "0    False\n",
        "1    False\n",
        "2     True\n",
        "3     True\n",
        "4    False\n",
        "5    False\n",
        "6    False\n",
        "7    False\n",
        "8     True\n",
        "Name: spp, dtype: bool"
       ]
      }
     ],
     "prompt_number": 144
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Combining Data Frames\n",
      "To run statistics comparing these two groups, it might be helpful if they were in the same dataframe, with an additional column describing the source. How do we add a column?  \n",
      "\n",
      "Pandas has two method that can be used for this. The historical, function is 'append()', and the newer and more complex version is 'concatenate()'. I really should put the Pandas documentation by my bed..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bare = pd.concat([bare1, bare2], axis=0, keys=['GC', 'TS'])\n",
      "bare.dropna(axis=1, how='all')\n",
      "bare = bare[['date', 'percent','season','transect']]\n",
      "bare"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th>date</th>\n",
        "      <th>percent</th>\n",
        "      <th>season</th>\n",
        "      <th>transect</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th rowspan=\"3\" valign=\"top\">GC</th>\n",
        "      <th>1</th>\n",
        "      <td> 8/23/2002</td>\n",
        "      <td> 35</td>\n",
        "      <td> Summer</td>\n",
        "      <td>  1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 8/23/2002</td>\n",
        "      <td> 40</td>\n",
        "      <td> Summer</td>\n",
        "      <td> 3A</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5</th>\n",
        "      <td> 5/16/2003</td>\n",
        "      <td> 15</td>\n",
        "      <td> SPRING</td>\n",
        "      <td> 1A</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th rowspan=\"3\" valign=\"top\">TS</th>\n",
        "      <th>2</th>\n",
        "      <td>  5/2/2002</td>\n",
        "      <td> 98</td>\n",
        "      <td> Spring</td>\n",
        "      <td> 1A</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>  5/2/2002</td>\n",
        "      <td> 89</td>\n",
        "      <td> Spring</td>\n",
        "      <td>  2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8</th>\n",
        "      <td> 8/19/2002</td>\n",
        "      <td> 30</td>\n",
        "      <td> Summer</td>\n",
        "      <td>  2</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>6 rows \u00d7 4 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 116,
       "text": [
        "           date  percent  season transect\n",
        "GC 1  8/23/2002       35  Summer        1\n",
        "   4  8/23/2002       40  Summer       3A\n",
        "   5  5/16/2003       15  SPRING       1A\n",
        "TS 2   5/2/2002       98  Spring       1A\n",
        "   3   5/2/2002       89  Spring        2\n",
        "   8  8/19/2002       30  Summer        2\n",
        "\n",
        "[6 rows x 4 columns]"
       ]
      }
     ],
     "prompt_number": 116
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##General statistics"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If the data in the column is numeric, you can use `describe()` to get some stats on it. In fact, each of the summary statistics that `describe()` prints out, we can apply easily to any column or subset of the data on its own. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df1.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>east</th>\n",
        "      <th>north</th>\n",
        "      <th>year</th>\n",
        "      <th>quad</th>\n",
        "      <th>dist</th>\n",
        "      <th>waterdepth</th>\n",
        "      <th>percent</th>\n",
        "      <th>height</th>\n",
        "      <th>comments</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>count</th>\n",
        "      <td>      9.000000</td>\n",
        "      <td>       9.000000</td>\n",
        "      <td>    9.000000</td>\n",
        "      <td>  9.000000</td>\n",
        "      <td>  9.000000</td>\n",
        "      <td>  2.000000</td>\n",
        "      <td>   9.000000</td>\n",
        "      <td>  5.00000</td>\n",
        "      <td>  0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>mean</th>\n",
        "      <td> 549717.000000</td>\n",
        "      <td> 4219805.000000</td>\n",
        "      <td> 2002.444444</td>\n",
        "      <td>  7.555556</td>\n",
        "      <td> 21.000000</td>\n",
        "      <td> 28.000000</td>\n",
        "      <td>  35.111111</td>\n",
        "      <td> 26.60000</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>std</th>\n",
        "      <td>    135.412333</td>\n",
        "      <td>     103.621909</td>\n",
        "      <td>    0.527046</td>\n",
        "      <td>  4.530759</td>\n",
        "      <td> 12.639225</td>\n",
        "      <td> 36.769553</td>\n",
        "      <td>  29.645592</td>\n",
        "      <td> 11.21606</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>min</th>\n",
        "      <td> 549526.000000</td>\n",
        "      <td> 4219628.000000</td>\n",
        "      <td> 2002.000000</td>\n",
        "      <td>  1.000000</td>\n",
        "      <td>  6.000000</td>\n",
        "      <td>  2.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>  8.00000</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25%</th>\n",
        "      <td> 549716.000000</td>\n",
        "      <td> 4219834.000000</td>\n",
        "      <td> 2002.000000</td>\n",
        "      <td>  3.000000</td>\n",
        "      <td>  6.000000</td>\n",
        "      <td> 15.000000</td>\n",
        "      <td>  15.000000</td>\n",
        "      <td> 24.00000</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>50%</th>\n",
        "      <td> 549717.000000</td>\n",
        "      <td> 4219841.000000</td>\n",
        "      <td> 2002.000000</td>\n",
        "      <td>  8.000000</td>\n",
        "      <td> 24.000000</td>\n",
        "      <td> 28.000000</td>\n",
        "      <td>  25.000000</td>\n",
        "      <td> 33.00000</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>75%</th>\n",
        "      <td> 549717.000000</td>\n",
        "      <td> 4219841.000000</td>\n",
        "      <td> 2003.000000</td>\n",
        "      <td> 10.000000</td>\n",
        "      <td> 27.000000</td>\n",
        "      <td> 41.000000</td>\n",
        "      <td>  40.000000</td>\n",
        "      <td> 34.00000</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>max</th>\n",
        "      <td> 549909.000000</td>\n",
        "      <td> 4219899.000000</td>\n",
        "      <td> 2003.000000</td>\n",
        "      <td> 14.000000</td>\n",
        "      <td> 39.000000</td>\n",
        "      <td> 54.000000</td>\n",
        "      <td> 100.000000</td>\n",
        "      <td> 34.00000</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>8 rows \u00d7 9 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 73,
       "text": [
        "                east           north         year       quad       dist  \\\n",
        "count       9.000000        9.000000     9.000000   9.000000   9.000000   \n",
        "mean   549717.000000  4219805.000000  2002.444444   7.555556  21.000000   \n",
        "std       135.412333      103.621909     0.527046   4.530759  12.639225   \n",
        "min    549526.000000  4219628.000000  2002.000000   1.000000   6.000000   \n",
        "25%    549716.000000  4219834.000000  2002.000000   3.000000   6.000000   \n",
        "50%    549717.000000  4219841.000000  2002.000000   8.000000  24.000000   \n",
        "75%    549717.000000  4219841.000000  2003.000000  10.000000  27.000000   \n",
        "max    549909.000000  4219899.000000  2003.000000  14.000000  39.000000   \n",
        "\n",
        "       waterdepth     percent    height  comments  \n",
        "count    2.000000    9.000000   5.00000         0  \n",
        "mean    28.000000   35.111111  26.60000       NaN  \n",
        "std     36.769553   29.645592  11.21606       NaN  \n",
        "min      2.000000    1.000000   8.00000       NaN  \n",
        "25%     15.000000   15.000000  24.00000       NaN  \n",
        "50%     28.000000   25.000000  33.00000       NaN  \n",
        "75%     41.000000   40.000000  34.00000       NaN  \n",
        "max     54.000000  100.000000  34.00000       NaN  \n",
        "\n",
        "[8 rows x 9 columns]"
       ]
      }
     ],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df1.waterdepth.max()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 92,
       "text": [
        "54.0"
       ]
      }
     ],
     "prompt_number": 92
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The histogram function will plot a basic distribution of your data. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df1.percent.hist()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 91,
       "text": [
        "<matplotlib.axes.AxesSubplot at 0x106bf38d0>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEACAYAAAC57G0KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSLHgASBS/w+u/pVcaHtc5gAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x106bf0290>"
       ]
      }
     ],
     "prompt_number": 91
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can ask statistical questions of the dataset. What species has the densest growth by season? Let's break this down the pieces we can do:\n",
      "\n",
      "  1. find the max density\n",
      "  2. get the row with the max density\n",
      "  3. get the species from the row with the max density\n",
      "  \n",
      "If we could group our data by season, and apply this question to each group, we could answer the question. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Maximum\n",
      "We can use .max() to find the maximum value of a column, but how do we select out a row?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df2.density.max()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 88,
       "text": [
        "300.0"
       ]
      }
     ],
     "prompt_number": 88
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Groupby\n",
      "Count the frequencies of the observations of each species type."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# use groupby\n",
      "for species, tmpdat in df1.groupby('spp'):\n",
      "    print species, tmpdat.spp.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ATTR 1\n",
        "BARE 3\n",
        "MF 1\n",
        "RASA 1\n",
        "SAVI 3\n"
       ]
      }
     ],
     "prompt_number": 83
    }
   ],
   "metadata": {}
  }
 ]
}